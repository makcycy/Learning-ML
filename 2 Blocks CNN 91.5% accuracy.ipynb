{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN (2 Conv + 3 FC)",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdDn0Ri5loF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as pd\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaHeZxrolp0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqeju6tVlp8E",
        "colab_type": "code",
        "outputId": "4ba1f854-ab8c-4ff9-92aa-f1d58408ef95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    Conv2D(16, kernel_size=(3,3), input_shape=(28,28,1)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv2D(16, (3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(32, kernel_size=(3,3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv2D(32, (3,3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgRGVFPRlp-v",
        "colab_type": "code",
        "outputId": "19501199-8656-4469-e33d-f0c8c821feff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4218
        }
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "tpu_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tpu_model.fit(x_train, y_train, epochs=100, validation_split = 0.2, batch_size = 1000)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.68.184.90:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 842603616361852918)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15045354977837502284)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8682309123445925566)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1592209451195559192)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10337553898393922201)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6527659643161186558)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8957673690433955335)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9973849687522118129)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 798669433695086227)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16868803572242119081)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12301502119547603151)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Train on 60000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(125,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(125, 28, 28, 1), dtype=tf.float32, name='conv2d_input_10'), TensorSpec(shape=(125, 1), dtype=tf.int32, name='dense_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for conv2d_input\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f52980f0908> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 5.350387334823608 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "59000/60000 [============================>.] - ETA: 0s - loss: 1.8031 - acc: 0.3939INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(125,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(125, 28, 28, 1), dtype=tf.float32, name='conv2d_input_10'), TensorSpec(shape=(125, 1), dtype=tf.int32, name='dense_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for conv2d_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f529450a358> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 3.0437304973602295 secs\n",
            "60000/60000 [==============================] - 26s 441us/sample - loss: 1.7921 - acc: 0.3966 - val_loss: 2.2331 - val_acc: 0.1212\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.9479 - acc: 0.6522 - val_loss: 2.4065 - val_acc: 0.1308\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.7804 - acc: 0.7086 - val_loss: 2.5054 - val_acc: 0.1419\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6965 - acc: 0.7375 - val_loss: 2.2070 - val_acc: 0.2519\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6454 - acc: 0.7556 - val_loss: 1.7253 - val_acc: 0.4251\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6072 - acc: 0.7708 - val_loss: 1.3702 - val_acc: 0.5304\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.5775 - acc: 0.7838 - val_loss: 0.8527 - val_acc: 0.6868\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.5484 - acc: 0.7950 - val_loss: 0.6447 - val_acc: 0.7676\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.5293 - acc: 0.8033 - val_loss: 0.4788 - val_acc: 0.8306\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.5059 - acc: 0.8140 - val_loss: 0.4251 - val_acc: 0.8469\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.4886 - acc: 0.8212 - val_loss: 0.3848 - val_acc: 0.8582\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4731 - acc: 0.8262 - val_loss: 0.3749 - val_acc: 0.8613\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.4599 - acc: 0.8310 - val_loss: 0.3607 - val_acc: 0.8673\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.4532 - acc: 0.8360 - val_loss: 0.3735 - val_acc: 0.8597\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.4399 - acc: 0.8390 - val_loss: 0.3404 - val_acc: 0.8753\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4311 - acc: 0.8436 - val_loss: 0.3290 - val_acc: 0.8781\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.4217 - acc: 0.8469 - val_loss: 0.3224 - val_acc: 0.8798\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4101 - acc: 0.8517 - val_loss: 0.3237 - val_acc: 0.8814\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.4059 - acc: 0.8517 - val_loss: 0.3241 - val_acc: 0.8822\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3982 - acc: 0.8552 - val_loss: 0.3169 - val_acc: 0.8836\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3935 - acc: 0.8591 - val_loss: 0.2956 - val_acc: 0.8882\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3884 - acc: 0.8597 - val_loss: 0.2834 - val_acc: 0.8952\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3835 - acc: 0.8615 - val_loss: 0.2958 - val_acc: 0.8912\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3812 - acc: 0.8624 - val_loss: 0.3004 - val_acc: 0.8895\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 42us/sample - loss: 0.3769 - acc: 0.8632 - val_loss: 0.2992 - val_acc: 0.8907\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3719 - acc: 0.8655 - val_loss: 0.2818 - val_acc: 0.8979\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3653 - acc: 0.8671 - val_loss: 0.2835 - val_acc: 0.8961\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3584 - acc: 0.8709 - val_loss: 0.2714 - val_acc: 0.8972\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3560 - acc: 0.8717 - val_loss: 0.2671 - val_acc: 0.8999\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3543 - acc: 0.8718 - val_loss: 0.2639 - val_acc: 0.9003\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3557 - acc: 0.8727 - val_loss: 0.2597 - val_acc: 0.9014\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3481 - acc: 0.8750 - val_loss: 0.2609 - val_acc: 0.9019\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3442 - acc: 0.8764 - val_loss: 0.2599 - val_acc: 0.9027\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3430 - acc: 0.8761 - val_loss: 0.2622 - val_acc: 0.9040\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3394 - acc: 0.8776 - val_loss: 0.2549 - val_acc: 0.9053\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3379 - acc: 0.8778 - val_loss: 0.2560 - val_acc: 0.9015\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3347 - acc: 0.8792 - val_loss: 0.2479 - val_acc: 0.9069\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3346 - acc: 0.8791 - val_loss: 0.2569 - val_acc: 0.9022\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3368 - acc: 0.8789 - val_loss: 0.2522 - val_acc: 0.9067\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3289 - acc: 0.8813 - val_loss: 0.2502 - val_acc: 0.9070\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3294 - acc: 0.8806 - val_loss: 0.2391 - val_acc: 0.9128\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3284 - acc: 0.8812 - val_loss: 0.2422 - val_acc: 0.9080\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3225 - acc: 0.8834 - val_loss: 0.2361 - val_acc: 0.9128\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3214 - acc: 0.8847 - val_loss: 0.2404 - val_acc: 0.9078\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3209 - acc: 0.8849 - val_loss: 0.2317 - val_acc: 0.9116\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3197 - acc: 0.8849 - val_loss: 0.2328 - val_acc: 0.9122\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3180 - acc: 0.8850 - val_loss: 0.2315 - val_acc: 0.9152\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3195 - acc: 0.8856 - val_loss: 0.2358 - val_acc: 0.9126\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3159 - acc: 0.8858 - val_loss: 0.2358 - val_acc: 0.9093\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3131 - acc: 0.8879 - val_loss: 0.2315 - val_acc: 0.9138\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3114 - acc: 0.8878 - val_loss: 0.2326 - val_acc: 0.9137\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3104 - acc: 0.8889 - val_loss: 0.2261 - val_acc: 0.9136\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3110 - acc: 0.8881 - val_loss: 0.2336 - val_acc: 0.9123\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3054 - acc: 0.8884 - val_loss: 0.2254 - val_acc: 0.9137\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3073 - acc: 0.8891 - val_loss: 0.2205 - val_acc: 0.9178\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3072 - acc: 0.8883 - val_loss: 0.2239 - val_acc: 0.9158\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3037 - acc: 0.8885 - val_loss: 0.2140 - val_acc: 0.9214\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3031 - acc: 0.8907 - val_loss: 0.2243 - val_acc: 0.9165\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3029 - acc: 0.8895 - val_loss: 0.2226 - val_acc: 0.9173\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2981 - acc: 0.8919 - val_loss: 0.2235 - val_acc: 0.9183\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3019 - acc: 0.8917 - val_loss: 0.2147 - val_acc: 0.9202\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2973 - acc: 0.8925 - val_loss: 0.2136 - val_acc: 0.9189\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2973 - acc: 0.8905 - val_loss: 0.2165 - val_acc: 0.9179\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2993 - acc: 0.8923 - val_loss: 0.2118 - val_acc: 0.9194\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2948 - acc: 0.8931 - val_loss: 0.2147 - val_acc: 0.9180\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2944 - acc: 0.8940 - val_loss: 0.2259 - val_acc: 0.9145\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2962 - acc: 0.8932 - val_loss: 0.2225 - val_acc: 0.9160\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2903 - acc: 0.8952 - val_loss: 0.2062 - val_acc: 0.9225\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2903 - acc: 0.8952 - val_loss: 0.2066 - val_acc: 0.9241\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2896 - acc: 0.8952 - val_loss: 0.2066 - val_acc: 0.9201\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2919 - acc: 0.8939 - val_loss: 0.2159 - val_acc: 0.9205\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2929 - acc: 0.8950 - val_loss: 0.2057 - val_acc: 0.9234\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2888 - acc: 0.8954 - val_loss: 0.2207 - val_acc: 0.9140\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2898 - acc: 0.8957 - val_loss: 0.2037 - val_acc: 0.9234\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2868 - acc: 0.8968 - val_loss: 0.2077 - val_acc: 0.9202\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2898 - acc: 0.8949 - val_loss: 0.2086 - val_acc: 0.9232\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2885 - acc: 0.8948 - val_loss: 0.2124 - val_acc: 0.9213\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2868 - acc: 0.8963 - val_loss: 0.1974 - val_acc: 0.9258\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2869 - acc: 0.8960 - val_loss: 0.2025 - val_acc: 0.9247\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2837 - acc: 0.8980 - val_loss: 0.2112 - val_acc: 0.9207\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2854 - acc: 0.8970 - val_loss: 0.2000 - val_acc: 0.9247\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2809 - acc: 0.8995 - val_loss: 0.1960 - val_acc: 0.9258\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2823 - acc: 0.8983 - val_loss: 0.1953 - val_acc: 0.9269\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2803 - acc: 0.8989 - val_loss: 0.2034 - val_acc: 0.9245\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2805 - acc: 0.8974 - val_loss: 0.1998 - val_acc: 0.9253\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2828 - acc: 0.8975 - val_loss: 0.2132 - val_acc: 0.9202\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2792 - acc: 0.8983 - val_loss: 0.2000 - val_acc: 0.9241\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2810 - acc: 0.8985 - val_loss: 0.2116 - val_acc: 0.9211\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2781 - acc: 0.9004 - val_loss: 0.2038 - val_acc: 0.9238\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2812 - acc: 0.8981 - val_loss: 0.2008 - val_acc: 0.9236\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2765 - acc: 0.8995 - val_loss: 0.1968 - val_acc: 0.9260\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2768 - acc: 0.9002 - val_loss: 0.1917 - val_acc: 0.9274\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2763 - acc: 0.9004 - val_loss: 0.2035 - val_acc: 0.9249\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2777 - acc: 0.9011 - val_loss: 0.1948 - val_acc: 0.9288\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2793 - acc: 0.8993 - val_loss: 0.2078 - val_acc: 0.9198\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2745 - acc: 0.8999 - val_loss: 0.1941 - val_acc: 0.9282\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2766 - acc: 0.9003 - val_loss: 0.1964 - val_acc: 0.9252\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2737 - acc: 0.9009 - val_loss: 0.1908 - val_acc: 0.9273\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2745 - acc: 0.8997 - val_loss: 0.1918 - val_acc: 0.9283\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2778 - acc: 0.8984 - val_loss: 0.1948 - val_acc: 0.9276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5298179898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGdIYR57lqBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "4522f032-8a31-47ac-cb32-1b044b44e7f9"
      },
      "source": [
        "tpu_model.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(4, 28, 28, 1), dtype=tf.float32, name='conv2d_input_10'), TensorSpec(shape=(4, 1), dtype=tf.int32, name='dense_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for conv2d_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f529450a358> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.7379992008209229 secs\n",
            " 9856/10000 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9153INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 28, 28, 1), dtype=tf.float32, name='conv2d_input_10'), TensorSpec(shape=(2, 1), dtype=tf.int32, name='dense_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for conv2d_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f529450a358> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.8687779903411865 secs\n",
            "10000/10000 [==============================] - 8s 763us/sample - loss: 0.2314 - acc: 0.9150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23140989557504654, 0.91499996]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCXfz8BlqEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "5e40fc34-c411-42b2-ff30-bf0fddc11d01"
      },
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_input (InputLayer)    (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_1 (Ba (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_2 (Ba (None, 10, 10, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_3 (Ba (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 83,706\n",
            "Trainable params: 83,514\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}